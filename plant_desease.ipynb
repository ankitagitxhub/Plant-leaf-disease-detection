{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUqxOmbQkQbg",
        "outputId": "174dc936-5e3a-41a5-d6a0-e7079b7e4f8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries Imported Successfully\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
            "‚úÖ Data Loaded: (50000, 32, 32, 3) (50000, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CNN Model Built\n",
            "Epoch 1/5\n",
            "\u001b[1m 951/1563\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m28s\u001b[0m 47ms/step - accuracy: 0.3029 - loss: 1.8708"
          ]
        }
      ],
      "source": [
        "# Plant Disease Detection using CNN (Minimal Demo)\n",
        "# Author: Ankita Sahoo\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Import Libraries\n",
        "# -------------------------------\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"‚úÖ Libraries Imported Successfully\")\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Data Preparation (Dummy / Replace with Kaggle Dataset)\n",
        "# -------------------------------\n",
        "# For demo, using CIFAR-10 dataset (you can replace with plant dataset later)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print(\"‚úÖ Data Loaded:\", x_train.shape, y_train.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Build CNN Model\n",
        "# -------------------------------\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax')  # 10 classes (replace with disease classes)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(\"‚úÖ CNN Model Built\")\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Train Model\n",
        "# -------------------------------\n",
        "history = model.fit(x_train, y_train, epochs=5,\n",
        "                    validation_data=(x_test, y_test))\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Evaluate Model\n",
        "# -------------------------------\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"\\nüéØ Test Accuracy:\", test_acc)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Visualize Training\n",
        "# -------------------------------\n",
        "plt.plot(history.history['accuracy'], label='train_acc')\n",
        "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Prediction (Demo)\n",
        "# -------------------------------\n",
        "import numpy as np\n",
        "sample_img = x_test[0].reshape(1,32,32,3)\n",
        "prediction = model.predict(sample_img)\n",
        "print(\"Predicted Class:\", prediction.argmax())\n"
      ]
    }
  ]
}